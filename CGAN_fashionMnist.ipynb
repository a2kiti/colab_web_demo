{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CGAN_fashionMnist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a2kiti/colab_web_demo/blob/master/CGAN_fashionMnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "PYvu91hl98gO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist, fashion_mnist\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Conv2D, Conv2DTranspose\n",
        "from keras.layers import BatchNormalization, Activation, UpSampling2D, concatenate\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.models import Model, load_model\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from scipy.misc import imread, imsave\n",
        "import os\n",
        "import requests, json\n",
        "import io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_Vqzfdjv_hKr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_rows = 28 \n",
        "img_cols = 28\n",
        "channels = 1\n",
        "class_num = 10\n",
        "\n",
        "# Dimensions of latent variable\n",
        "z_dim = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R4A-QgnK_hlp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# discriminator model\n",
        "input_img = Input((img_rows, img_cols, channels + class_num))\n",
        "x = Conv2D(64, 4, strides=2, padding='same')(input_img)\n",
        "x = LeakyReLU(0.2)(x)\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "x = Conv2D(128, 4, strides=2, padding='same')(x)\n",
        "x = LeakyReLU(0.2)(x)\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "x = Conv2D(256, 4, strides=2, padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU(0.2)(x)\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "\n",
        "x = Dense(1)(x)\n",
        "x = Activation('sigmoid')(x)\n",
        "\n",
        "dis = Model(input_img, x, name=\"discriminator\")\n",
        "\n",
        "dis.summary()\n",
        "\n",
        "dis_optimizer = Adam(lr=1e-5, beta_1=0.1)\n",
        "dis.compile(loss='binary_crossentropy', optimizer=dis_optimizer, metrics=['accuracy'])\n",
        "dis.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WJ1s8138_zbZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generator model\n",
        "noise_shape = Input((z_dim + class_num,))\n",
        "\n",
        "x = Dense(128*7*7)(noise_shape)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU(0.2)(x)\n",
        "\n",
        "x = Reshape((7,7,128))(x)\n",
        "\n",
        "x = UpSampling2D((2,2))(x)\n",
        "x = Conv2DTranspose(filters=64, kernel_size=4, strides=1, padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU(0.2)(x)\n",
        "\n",
        "x = UpSampling2D((2,2))(x)\n",
        "x = Conv2DTranspose(filters=32, kernel_size=4, strides=1, padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU(0.2)(x)\n",
        "\n",
        "x = Conv2DTranspose(filters=channels, kernel_size=4, strides=1, padding='same')(x)\n",
        "x = Activation('tanh')(x)\n",
        "\n",
        "gen = Model(noise_shape, x, name=\"generator\")\n",
        "\n",
        "gen.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6M4kCuu-ALrW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "z = Input((z_dim,))\n",
        "label = Input((class_num,))\n",
        "label_img = Input((img_rows,img_cols,class_num,))\n",
        "\n",
        "z_with_label = concatenate([z, label], axis=-1)\n",
        "\n",
        "img = gen(z_with_label)\n",
        "img_with_label = concatenate([img, label_img], axis=3)\n",
        "\n",
        "valid = dis(img_with_label)\n",
        "com = Model([z, label, label_img], valid, name=\"combined\")\n",
        "com.summary()\n",
        "\n",
        "com_optimizer = Adam(lr=.8e-4, beta_1=0.5)\n",
        "com.compile(loss='binary_crossentropy', optimizer=com_optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-SN5cm2BAkD5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loading mnist\n",
        "(X_train, y_train), (_, _) = fashion_mnist.load_data()\n",
        "# (X_train, y_train), (_, _) = mnist.load_data()\n",
        "\n",
        "# Normalization\n",
        "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
        "X_train = np.expand_dims(X_train, axis=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8Pp7mbdnBb-C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Connecting to googledrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VGnc9J_KBeIC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "modelpath = 'gdrive/My Drive/Colab Notebooks/CGAN_model.hdf5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C9zs9lesAq7k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = 3000\n",
        "batch_size = 128\n",
        "save_interval=1000\n",
        "\n",
        "half_batch = int(batch_size / 2)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    # ---------------------\n",
        "    #  Training of Discriminator\n",
        "    # ---------------------\n",
        "\n",
        "    # Generating images from Generator\n",
        "    noise = np.random.normal(0, 1, (half_batch, z_dim))\n",
        "    noise_label_index = np.random.randint(0, class_num, half_batch)\n",
        "    noise_label = np.zeros((half_batch, class_num))\n",
        "    for i in range(half_batch):\n",
        "        noise_label[i, noise_label_index[i]] = 1\n",
        "    noise_with_label = np.concatenate((noise, noise_label),axis=1)\n",
        "\n",
        "    gen_imgs = gen.predict(noise_with_label)\n",
        "    label_imgs = np.zeros((half_batch, img_rows, img_cols, class_num))\n",
        "    for i in range(half_batch):\n",
        "        label_imgs[i, :, :, noise_label_index[i]] = 1\n",
        "    gen_imgs_with_label = np.concatenate((gen_imgs, label_imgs),axis=3)\n",
        "\n",
        "    # Picking from train data\n",
        "    idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
        "    imgs = X_train[idx]\n",
        "    label_imgs = np.zeros((half_batch, img_rows, img_cols, class_num))\n",
        "    for i in range(half_batch):\n",
        "        label_imgs[i, :, :, y_train[idx][i]] = 1\n",
        "    imgs_with_label = np.concatenate((imgs, label_imgs),axis=3)\n",
        "\n",
        "    \n",
        "    real_label = np.ones((half_batch, 1))\n",
        "    fake_label = np.zeros((half_batch, 1))\n",
        "    \n",
        "    d_loss_real = dis.train_on_batch(imgs_with_label, real_label)\n",
        "    d_loss_fake = dis.train_on_batch(gen_imgs_with_label, fake_label)\n",
        "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "    \n",
        "    # ---------------------\n",
        "    #  Training of Generator\n",
        "    # ---------------------\n",
        "\n",
        "    noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "    noise_label = np.zeros((batch_size, class_num))\n",
        "    noise_label_imgs = np.zeros((batch_size, img_rows, img_cols, class_num))\n",
        "    for i in range(batch_size):\n",
        "        label_index = np.random.randint(0,class_num)\n",
        "        noise_label[i, label_index] = 1\n",
        "        noise_label_imgs[i, :, :, label_index] = 1\n",
        "       \n",
        "    \n",
        "    valid_y = np.ones((batch_size, 1))\n",
        "\n",
        "    # Train the generator\n",
        "    g_loss = com.train_on_batch([noise, noise_label, noise_label_imgs], valid_y)\n",
        "\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sOCnLtLbKk35",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gen.save(modelpath)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}